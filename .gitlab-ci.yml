stages:
  - prepare
  - build:shared
  - build
  - build:docker
  - deploy
  - k8:verify
  - k8:debug

variables:
  # The suffix of the url (suffix.tld):
  # feature     branches: branch-name.suffix.tld
  # staging:    staging.suffix.tld
  # production: suffix.tld
  URL_SUFFIX: vcgc19.dbvis.de
  #
  # The namespace for kubernetes
  K8_NAMESPACE: jentner
  #
  # Deploy production on tags (yes / no)
  # If "no", the production deployment will be done when pushed to staging (e.g., master)
  DEPLOY_ON_TAGS: "no"
  #
  # Build and deploy feature branches (yes / no)
  DEPLOY_FB: "yes"
  #
  # The name of the staging branch
  STAGING_BRANCH: master
  #
  # Helm chart (default lingvis-generic-chart)
  HELM_CHART: registry.dbvis.de/lingvis/misc/generic-helm-chart
  #
  # Helm chart version
  HELM_CHART_VERSION: v2.0.0
  #
  # Dockerfile location (default in root)
  DOCKERFILE_LOC: ./deployment/Dockerfile
  #
  # Docker context (default root)
  DOCKER_CONTEXT: ./
  #
  # Helm image
  HELM_IMAGE: alpine/helm:3.2.4
  #
  # Kubectl image
  KUBECTL_IMAGE: bitnami/kubectl:1.17.4
  #
  # 
  REPLICA_COUNT_PRODUCTION: 1
  #
  #
  REPLICA_COUNT_STAGING: 1
  #
  #
  REPLICA_COUNT_FB: 1

###########################################
# DEFINE BRANCH TRIGGER RULES
###########################################

#--------------------
# Deployment
#--------------------

.rules: &rules
  rules:
    # do not run pipelines for merge requests (gets rid of "detatched pipelines")
    - if: $CI_MERGE_REQUEST_ID
      when: never
    # if this is set, run this job all the time
    - if: $RUN_ALWAYS == "yes"
      when: on_success
    # for feature branches
    - if: $DEPLOY_FB == "yes" && $RUN_ON_FB == "yes" && $CI_COMMIT_BRANCH != $STAGING_BRANCH && $CI_COMMIT_TAG == null
      when: on_success
    # if we want tags and it's a staging job
    - if: $DEPLOY_ON_TAGS == "yes" && $RUN_ON_MASTER == "yes" && $CI_COMMIT_BRANCH == $STAGING_BRANCH
      when: on_success
    # if we don't want tags and it's a production job
    - if: $DEPLOY_ON_TAGS == "no" && $RUN_ON_TAG == "yes" && $CI_COMMIT_BRANCH == $STAGING_BRANCH
      when: on_success
    # if we want tags and it is actually a tag
    - if: $DEPLOY_ON_TAGS == "yes" && $RUN_ON_TAG == "yes" && $CI_COMMIT_TAG =~ /^v.*/
      when: on_success
    # default is on_success, so explicitly set job not to run if none of the above rules matched
    - when: never

#--------------------
# Environment Cleanup
#--------------------

.rules-cleanup: &rules-cleanup
  rules:
    # do not run pipelines for merge requests (gets rid of "detatched pipelines")
    - if: $CI_MERGE_REQUEST_ID
      when: never
    # if this is set, run this job all the time
    - if: $RUN_ALWAYS == "yes"
      when: manual
    # run if files changed
    # and if it should run on a feature branch or it should run on master
    # - changes:
    #     - Backend/**/*
    #     - k8/Backend/**/*
    #     - .gitlab-ci.yml
    - if: $RUN_ON_FB == "yes" && $CI_COMMIT_BRANCH != $STAGING_BRANCH && $CI_COMMIT_TAG == null
      when: manual
      allow_failure: true
    # - changes:
    #     - Backend/**/*
    #     - k8/Backend/**/*
    #     - .gitlab-ci.yml
    - if: $RUN_ON_MASTER == "yes" && $CI_COMMIT_BRANCH == $STAGING_BRANCH
      when: manual
      allow_failure: true
    # default is on_success, so explicitly set job not to run if none of the above rules matched
    - when: never

###########################################
# SETUP ENVIRONMENT VARIALBES
###########################################

export-environment:
  image: debian:stretch-slim
  stage: prepare
  script:
    - echo $CI_COMMIT_BRANCH
    - echo $STAGING_BRANCH
    # set the version either as a tag (v0.0.1) or as a commit sha (74bac331)
    - if [[ ${CI_COMMIT_TAG} =~ ^v[0-9].[0-9].[0-9] ]]; then VERSION=${CI_COMMIT_TAG}; else VERSION=${CI_COMMIT_SHORT_SHA}; fi
    # the current URL suffix
    #- URL_SUFFIX="covis.dbvis.de" # defined in the variables section
    # this shortens the slug to 30 characters and removes all trailing dashes
    - SHORTENED_CI_COMMIT_REF_SLUG=$(echo ${CI_COMMIT_REF_SLUG} | tr / - | cut -c -30 |  sed -E 's#-+$##')
    - URL_PREFIX=""
    - URL_PROTOCOL="https"
    - ENV_TYPE="review"
    - REPLICA_COUNT="${REPLICA_COUNT_PRODUCTION}"
    - if [ "${DEPLOY_ON_TAGS}" == "yes" ] && [[ "${CI_COMMIT_TAG}" =~ ^v[0-9].[0-9].[0-9] ]]; then ENV_TYPE="production"; fi
    - if [ "${DEPLOY_ON_TAGS}" == "yes" ] && [ "${CI_COMMIT_BRANCH}" == "${STAGING_BRANCH}" ]; then ENV_TYPE="staging"; fi
    - if [ "${DEPLOY_ON_TAGS}" == "no" ] && [ "${CI_COMMIT_BRANCH}" == "${STAGING_BRANCH}" ]; then ENV_TYPE="production"; fi
    - if [ "${ENV_TYPE}" == "staging" ]; then URL_PREFIX="staging."; REPLICA_COUNT="${REPLICA_COUNT_STAGING}"; fi
    - if [ "${ENV_TYPE}" == "review" ]; then URL_PREFIX="${SHORTENED_CI_COMMIT_REF_SLUG}."; REPLICA_COUNT="${REPLICA_COUNT_FB}"; fi
    # Build the backend url: prefix.api.suffix
    - URL_BACKEND="${URL_PREFIX}${URL_SUFFIX}"
    # all the stuff into the var.env
    - echo "ENV_TYPE=${ENV_TYPE}" >> var.env
    - echo "VERSION=${VERSION}" >> var.env
    - echo "URL_PROTOCOL=${URL_PROTOCOL}" >> var.env
    - echo "URL_BACKEND=${URL_BACKEND}" >> var.env
    - echo "REPLICA_COUNT=${REPLICA_COUNT}" >> var.env
    # DEBUG
    - cat var.env
  artifacts:
    paths:
      - var.env
    expire_in: 300 days
  tags:
    - docker

###########################################
# BUILD
###########################################

build:shared:
  image: node:12
  stage: build:shared
  before_script:
    - npm i -g typescript
  script:
    - cd shared
    - tsc -b -v
  artifacts:
    paths:
      - ./shared/dist
  tags:
    - docker

build:client:
  image: node:12
  stage: build
  script:
    - cd ./client-code
    - npm ci
    - npm run-script build:prod
  dependencies:
    - export-environment
    - build:shared
  artifacts:
    paths:
      - ./server-code/public
  tags:
    - docker

build:server:
  image: node:12
  stage: build
  script:
    - cd ./server-code
    - npm ci
    - npm run-script build
  dependencies:
    - export-environment
    - build:shared
  artifacts:
    paths:
      - ./server-code/dist
    expire_in: 1 week
  tags:
    - docker

###########################################
# DOCKERIZE
###########################################

dockerize:
  stage: build:docker
  image: docker:latest
  services:
    - docker:dind
  script:
    # needed for VERSION
    - source var.env
    - echo "$CI_REGISTRY_PASSWORD" | docker login --username "$CI_REGISTRY_USER" --password-stdin $CI_REGISTRY
    # generate imagename using a lowercased foldername == app
    - IMG="${CI_REGISTRY_IMAGE}:${VERSION}"
    - docker build --build-arg VERSION=${VERSION} -t "$IMG" -f $DOCKERFILE_LOC $DOCKER_CONTEXT
    - docker push "$IMG"
  tags:
    - docker-build


###########################################
# DEPLOY
###########################################

.deploy-script: &deploy-template
  stage: deploy
  image:
    name: $HELM_IMAGE
    entrypoint: ["sh", "-c", "apk add bash sed && /bin/bash"]
  script:
    - echo $KUBECONFIG
    - source var.env
    # DEBUG
    - cat var.env
    - URL=${URL_BACKEND}
    # DEBUG
    - echo ${URL}
    # generates the chart name using the environment name, replace all / with -; result: review-backend-100-fancify-pipeline
    - RELEASE_NAME=$(echo ${CI_ENVIRONMENT_NAME} | tr / - | tr _ - | tr '[:upper:]' '[:lower:]' | cut -c -53 | sed -E 's#-+$##')
    # DEBUG
    - echo ${RELEASE_NAME}
    # write the url into the var.env file for the dynamic env url generation
    - echo "URL=${URL}" >> var.env
    # use chart name and the folder by uppercasing the first character of the app name; result: Backend
    - export HELM_EXPERIMENTAL_OCI=1
    - helm registry login -u ${HELM_CHART_PULL_USER} --password ${HELM_CHART_PULL_PW} ${HELM_CHART}
    - helm chart list
    - helm chart pull ${HELM_CHART}:${HELM_CHART_VERSION}
    - helm chart export ${HELM_CHART}:${HELM_CHART_VERSION}
    - helm upgrade --namespace=${K8_NAMESPACE} --dry-run --debug --install -f values.yaml --set app.image.tag="${VERSION}" --set app.ingress.url=${URL} --set app.replicaCount=${REPLICA_COUNT} --set app.image.name=${CI_REGISTRY_IMAGE} ${RELEASE_NAME} ./lingvis-generic
    - helm upgrade --namespace=${K8_NAMESPACE} --install -f values.yaml --set app.image.tag="${VERSION}" --set app.ingress.url=${URL} --set app.replicaCount=${REPLICA_COUNT} --set app.image.name=${CI_REGISTRY_IMAGE} ${RELEASE_NAME} ./lingvis-generic
    - helm upgrade --namespace=${K8_NAMESPACE} --install --debug -f values-rethinkdb.yaml "${RELEASE_NAME}-rethinkdb" ./lingvis-generic
  tags:
    - docker

.deploy:
  <<: *deploy-template
  <<: *rules
  variables:
    RUN_ON_FB: "no"
    RUN_ON_MASTER: "no"
    RUN_ON_TAG: "no"
  environment:
    url: $URL_PROTOCOL://$URL
    name: $ENV_TYPE/$CI_PROJECT_NAME/$CI_COMMIT_REF_SLUG
    kubernetes:
      namespace: $K8_NAMESPACE
  artifacts:
    reports:
      dotenv: var.env

deploy-fb:
  extends: .deploy
  variables:
    ENV_TYPE: review
    RUN_ON_FB: "yes"
  environment:
    on_stop: remove-deployment-fb

deploy-staging:
  extends: .deploy
  variables:
    ENV_TYPE: staging
    RUN_ON_MASTER: "yes"

deploy-production:
  extends: .deploy
  variables:
    ENV_TYPE: production
    RUN_ON_TAG: "yes"
  environment:
    name: $ENV_TYPE/$CI_PROJECT_NAME


###########################################
# VERIFY & DEBUG
###########################################

verify successful k8 deployment:
  stage: k8:verify
  image: alpine:latest
  dependencies:
    - export-environment
  before_script:
    - apk add --update curl
  script:
    - source var.env
    # DEBUG
    - cat var.env
    - URL=${URL_BACKEND}
    - curl -v --fail --connect-timeout 10 --max-time 10 --retry 20 --retry-delay 10 --retry-max-time 120 "${URL}"
  retry: 2

debug k8 cluster state:
  stage: k8:debug
  image:
    name: $KUBECTL_IMAGE
    entrypoint: [""]
  environment:
    url: $URL_PROTOCOL://$URL
    name: $ENV_TYPE/$CI_PROJECT_NAME/$CI_COMMIT_REF_SLUG
    kubernetes:
      namespace: $K8_NAMESPACE
  script:
    - source var.env
    # generates the chart name using the environment name, replace all / with -; result: review-backend-100-fancify-pipeline
    - RELEASE_NAME=$(echo ${CI_ENVIRONMENT_NAME} | tr / - | tr _ - | tr '[:upper:]' '[:lower:]' | cut -c -53 | sed -E 's#-+$##')
    # DEBUG
    - echo ${RELEASE_NAME}
    - "kubectl describe node || :"
    - "kubectl -n ${K8_NAMESPACE} describe service \"${RELEASE_NAME}\" || :"
    - "kubectl -n ${K8_NAMESPACE} describe ingress \"${RELEASE_NAME}\" || :"
    - "kubectl -n ${K8_NAMESPACE} describe deployment \"${RELEASE_NAME}\" || :"
    - "kubectl -n ${K8_NAMESPACE} describe replicaset \"${RELEASE_NAME}\" || :"
    - "kubectl -n ${K8_NAMESPACE} describe pod \"${RELEASE_NAME}\" || :"
    - "kubectl -n ${K8_NAMESPACE} describe pvc \"${RELEASE_NAME}\" || :"
    - "kubectl -n ${K8_NAMESPACE} describe pv \"${RELEASE_NAME}\" || :"
    - "kubectl logs $(kubectl -n ${K8_NAMESPACE} get pods | awk -v pattern=\"${RELEASE_NAME}\" '$0 ~ pattern {print $1;exit}') || :"
  when: always
  tags:
    - docker
  allow_failure: true

###########################################
# CLEANUP NEW ENV
###########################################

.remove-deployment:
  stage: deploy
  image:
    name: $HELM_IMAGE
    entrypoint: ["sh", "-c", "apk add bash && /bin/bash"]
  variables:
    GIT_STRATEGY: none
    RUN_ON_FB: "no"
    RUN_ON_MASTER: "no"
    RUN_ON_TAG: "no"
  script:
    - echo $KUBECONFIG
    - RELEASE_NAME=$(echo "${ENV_TYPE}/$CI_PROJECT_NAME/${CI_COMMIT_REF_SLUG}" | tr / - | cut -c -53 | sed -E 's#-+$##')
    # DEBUG
    - echo $RELEASE_NAME
    - helm delete --namespace=${K8_NAMESPACE} --dry-run --debug ${RELEASE_NAME}
    - helm delete --namespace=${K8_NAMESPACE} ${RELEASE_NAME}
    - helm delete --namespace=${K8_NAMESPACE} "${RELEASE_NAME}-rethinkdb"
  dependencies: []
  allow_failure: true
  tags:
    - docker

remove-deployment-fb:
  extends: .remove-deployment
  <<: *rules-cleanup
  variables:
    APP: backend
    ENV_TYPE: review
    RUN_ON_FB: "yes"
  environment:
    name: $ENV_TYPE/$CI_PROJECT_NAME/$CI_COMMIT_REF_SLUG
    action: stop
